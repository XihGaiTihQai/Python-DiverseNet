{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180016dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09b8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aug(size=(256,256)):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ])\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir=None, size=(256,256), filter_white=False, aug=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.size = size\n",
    "        # Lấy đúng .jpg cho ảnh, .png cho mask\n",
    "        self.imgs = sorted([f for f in os.listdir(img_dir) if f.lower().endswith('.jpg')])\n",
    "        if filter_white:\n",
    "            imgs_valid = []\n",
    "            for fname in self.imgs:\n",
    "                img = Image.open(os.path.join(img_dir, fname)).convert('RGB').resize(size)\n",
    "                arr = np.array(img)\n",
    "                percent_white = ((arr > 240).all(axis=-1).sum()) / (arr.shape[0]*arr.shape[1])\n",
    "                if percent_white < 0.9:\n",
    "                    imgs_valid.append(fname)\n",
    "            self.imgs = imgs_valid\n",
    "        # mask sẽ map dựa theo tên gốc\n",
    "        self.masks = None\n",
    "        if mask_dir:\n",
    "            self.masks = [f.replace('_sat.jpg', '_mask.png') for f in self.imgs]\n",
    "        self.img_tf = get_aug(size) if aug else transforms.Compose([\n",
    "            transforms.Resize(self.size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.img_dir, self.imgs[idx])).convert('RGB')\n",
    "        img = self.img_tf(img)\n",
    "        if self.masks:\n",
    "            mask_path = os.path.join(self.mask_dir, self.masks[idx])\n",
    "            mask = Image.open(mask_path).convert('L').resize(self.size, Image.NEAREST)\n",
    "            mask = torch.from_numpy((np.array(mask) > 127).astype(np.uint8)).long()\n",
    "            return img, mask\n",
    "        else:\n",
    "            return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f8a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiverseHeadNet(nn.Module):\n",
    "    def __init__(self, num_classes=2, num_heads=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(2048, 256, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout2d(dropout),\n",
    "                nn.Conv2d(256, num_classes, 1)\n",
    "            ) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.num_heads = num_heads\n",
    "    def forward(self, x):\n",
    "        features = self.backbone.backbone(x)['out']\n",
    "        return [head(features) for head in self.heads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad1e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_pseudo_label(head_outputs, phi=1.5, conf_thresh=0.85):\n",
    "    stack = torch.stack([torch.softmax(o, dim=1) for o in head_outputs], dim=0)\n",
    "    mean_pred = torch.mean(stack, dim=0)\n",
    "    mean_label = torch.argmax(mean_pred, dim=1)\n",
    "    mean_conf = mean_pred.max(dim=1)[0]\n",
    "    pseudo_labels = [torch.argmax(o, dim=1) for o in head_outputs]\n",
    "    votes = torch.zeros_like(mean_label, dtype=torch.float)\n",
    "    for pl in pseudo_labels:\n",
    "        votes += (pl == mean_label).float()\n",
    "    votes = votes + phi\n",
    "    final_label = (votes > (len(head_outputs)//2)).long()\n",
    "    ignore_mask = (mean_conf < conf_thresh)\n",
    "    final_label[ignore_mask] = 255\n",
    "    return final_label\n",
    "\n",
    "def dice_loss(pred, target, smooth=1.):\n",
    "    pred = torch.softmax(pred, dim=1)[:,1]\n",
    "    mask = (target == 1).float()\n",
    "    pred = pred * (target != 255).float()\n",
    "    mask = mask * (target != 255).float()\n",
    "    intersection = (pred * mask).sum()\n",
    "    union = pred.sum() + mask.sum()\n",
    "    return 1 - ((2. * intersection + smooth) / (union + smooth))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_index)\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = self.ce(input, target)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = ((1-pt)**self.gamma) * ce_loss\n",
    "        return loss.mean()\n",
    "\n",
    "def compute_miou(pred_mask, gt_mask, n_classes=2):\n",
    "    ious = []\n",
    "    for cls in range(n_classes):\n",
    "        pred_i = (pred_mask == cls)\n",
    "        gt_i   = (gt_mask == cls)\n",
    "        inter = (pred_i & gt_i).sum()\n",
    "        union = (pred_i | gt_i).sum()\n",
    "        if union == 0:\n",
    "            iou = float('nan')\n",
    "        else:\n",
    "            iou = inter / union\n",
    "        ious.append(iou)\n",
    "    ious = [iou for iou in ious if not np.isnan(iou)]\n",
    "    if len(ious) == 0: return 0.0\n",
    "    return np.mean(ious)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_dataset_miou(model, dataset, device, n_classes=2, max_samples=None):\n",
    "    model.eval()\n",
    "    miou_list = []\n",
    "    N = len(dataset) if max_samples is None else min(len(dataset), max_samples)\n",
    "    for i in range(N):\n",
    "        img, mask = dataset[i]\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        out = model(img)\n",
    "        out_up = [nn.functional.interpolate(o, size=mask.shape[-2:], mode='bilinear', align_corners=False) for o in out]\n",
    "        mean_pred = torch.mean(torch.stack([torch.softmax(o, dim=1) for o in out_up]), dim=0)\n",
    "        pred_mask = torch.argmax(mean_pred, dim=1)[0].cpu().numpy()\n",
    "        miou = compute_miou(pred_mask, mask.cpu().numpy(), n_classes)\n",
    "        miou_list.append(miou)\n",
    "    return np.nanmean(miou_list)\n",
    "\n",
    "def refine_mask(mask_np):\n",
    "    mask_np = mask_np.astype(np.uint8)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask_np = cv2.morphologyEx(mask_np, cv2.MORPH_OPEN, kernel)\n",
    "    mask_np = cv2.morphologyEx(mask_np, cv2.MORPH_CLOSE, kernel)\n",
    "    return mask_np\n",
    "\n",
    "def filter_small_blob(mask_np, min_area=100):\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_np.astype(np.uint8), connectivity=8)\n",
    "    filtered = np.zeros_like(mask_np)\n",
    "    for i in range(1, n_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            filtered[labels == i] = 1\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aecbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_semi(\n",
    "    model, loader_l, loader_u, val_ds, optimizer, device,\n",
    "    num_epochs=20, lambda_u=0.05, conf_thresh=0.85, warmup_epochs=4\n",
    "):\n",
    "    num_fg, num_bg = 0, 0\n",
    "    for i in range(len(loader_l.dataset)):\n",
    "        _, mask = loader_l.dataset[i]\n",
    "        num_fg += (mask==1).sum().item()\n",
    "        num_bg += (mask==0).sum().item()\n",
    "    weight_bg = 1.0\n",
    "    weight_fg = num_bg / (num_fg + 1e-8) if num_fg > 0 else 1.0\n",
    "    weight_fg = min(weight_fg, 10.0)\n",
    "    class_weights = torch.tensor([weight_bg, weight_fg]).to(device)\n",
    "    print(f\"== Class weights for loss: bg={weight_bg:.2f}, fg={weight_fg:.2f}\")\n",
    "\n",
    "    criterion = FocalLoss(gamma=2, weight=class_weights, ignore_index=255)\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        iter_u = iter(loader_u)\n",
    "        for imgs_l, masks_l in loader_l:\n",
    "            imgs_l, masks_l = imgs_l.to(device), masks_l.to(device)\n",
    "            try:\n",
    "                imgs_u = next(iter_u)\n",
    "            except StopIteration:\n",
    "                iter_u = iter(loader_u)\n",
    "                imgs_u = next(iter_u)\n",
    "            imgs_u = imgs_u.to(device)\n",
    "            num_heads = model.num_heads\n",
    "            frozen = np.random.choice(num_heads, num_heads // 2, replace=False)\n",
    "            for i, head in enumerate(model.heads):\n",
    "                for p in head.parameters():\n",
    "                    p.requires_grad = False if i in frozen else True\n",
    "\n",
    "            outputs_l = model(imgs_l)\n",
    "            out_size = masks_l.shape[-2:]\n",
    "            outputs_l_up = [nn.functional.interpolate(o, size=out_size, mode='bilinear', align_corners=False) for o in outputs_l]\n",
    "            loss_sup = sum([\n",
    "                0.5 * criterion(o, masks_l) + 0.5 * dice_loss(o, masks_l)\n",
    "                for o in outputs_l_up\n",
    "            ]) / num_heads\n",
    "\n",
    "            if epoch < warmup_epochs:\n",
    "                loss = loss_sup\n",
    "            else:\n",
    "                outputs_u = model(imgs_u)\n",
    "                outputs_u_up = [nn.functional.interpolate(o, size=out_size, mode='bilinear', align_corners=False) for o in outputs_u]\n",
    "                pseudo_label = voting_pseudo_label(outputs_u_up, conf_thresh=conf_thresh)\n",
    "                head_idx = np.random.choice([i for i in range(num_heads) if i not in frozen])\n",
    "                out_main = outputs_u_up[head_idx]\n",
    "                loss_unsup = 0.5 * criterion(out_main, pseudo_label) + 0.5 * dice_loss(out_main, pseudo_label)\n",
    "                loss = loss_sup + lambda_u * loss_unsup\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            for head in model.heads:\n",
    "                for p in head.parameters():\n",
    "                    p.requires_grad = True\n",
    "\n",
    "        miou_train = eval_dataset_miou(model, loader_l.dataset, device, n_classes=2, max_samples=10)\n",
    "        miou_val = eval_dataset_miou(model, val_ds, device, n_classes=2)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: loss={loss.item():.4f}, mIoU_train={miou_train:.4f}, mIoU_val={miou_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18db3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predict(model, ds, device, title=''):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img, mask = ds[0]\n",
    "        img_vis = img * torch.tensor(IMAGENET_STD).view(3,1,1) + torch.tensor(IMAGENET_MEAN).view(3,1,1)\n",
    "        img_vis = (img_vis * 255).clip(0,255).byte().permute(1,2,0).cpu().numpy()\n",
    "        out = model(img.unsqueeze(0).to(device))\n",
    "        out_up = [nn.functional.interpolate(o, size=mask.shape[-2:], mode='bilinear', align_corners=False) for o in out]\n",
    "        mean_pred = torch.mean(torch.stack([torch.softmax(o, dim=1) for o in out_up]), dim=0)\n",
    "        pred_mask = torch.argmax(mean_pred, dim=1)[0].cpu().numpy()\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1,3,1); plt.imshow(img_vis); plt.title(f'{title} Image')\n",
    "        plt.subplot(1,3,2); plt.imshow(mask.cpu()); plt.title(f'{title} Mask')\n",
    "        plt.subplot(1,3,3); plt.imshow(pred_mask); plt.title(f'{title} Predict')\n",
    "        plt.show()\n",
    "\n",
    "def predict_and_save_unlabel(model, unlabel_folder, save_folder, device, size=(256,256)):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    ds_unlabel = SegmentationDataset(unlabel_folder, size=size, filter_white=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(ds_unlabel)):\n",
    "            img = ds_unlabel[idx].unsqueeze(0).to(device)\n",
    "            out = model(img)\n",
    "            out_up = [nn.functional.interpolate(o, size=size, mode='bilinear', align_corners=False) for o in out]\n",
    "            mean_pred = torch.mean(torch.stack([torch.softmax(o, dim=1) for o in out_up]), dim=0)\n",
    "            pred_mask = torch.argmax(mean_pred, dim=1).squeeze().cpu().numpy().astype(np.uint8)\n",
    "            pred_mask = refine_mask(pred_mask)\n",
    "            pred_mask = filter_small_blob(pred_mask, min_area=60)\n",
    "            fname = os.path.splitext(ds_unlabel.imgs[idx])[0]\n",
    "            Image.fromarray(pred_mask * 255).save(os.path.join(save_folder, fname + '_pred.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    num_classes = 2\n",
    "    num_heads = 8\n",
    "    batch_size = 4\n",
    "\n",
    "    train_img = 'road2/train_have_label_img'\n",
    "    train_mask = 'road2/train_have_label_mask'\n",
    "    val_img = 'road2/val_img'\n",
    "    val_mask = 'road2/val_mask'\n",
    "    unlabel_img = 'road2/train_unlabel'\n",
    "\n",
    "    ds_l = SegmentationDataset(train_img, train_mask, size=(256,256), aug=True)\n",
    "    ds_val = SegmentationDataset(val_img, val_mask, size=(256,256))\n",
    "    ds_u = SegmentationDataset(unlabel_img, size=(256,256), filter_white=True, aug=True)\n",
    "\n",
    "    loader_l = DataLoader(ds_l, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    loader_u = DataLoader(ds_u, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    loader_val = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = DiverseHeadNet(num_classes=num_classes, num_heads=num_heads, dropout=0.3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    train_semi(\n",
    "        model, loader_l, loader_u, ds_val, optimizer, device,\n",
    "        num_epochs=20, lambda_u=0.05, conf_thresh=0.85, warmup_epochs=4\n",
    "    )\n",
    "    print(\"\\n== mIoU TRAIN ==\", eval_dataset_miou(model, ds_l, device, n_classes=2))\n",
    "    print(\"== mIoU VAL  ==\", eval_dataset_miou(model, ds_val, device, n_classes=2))\n",
    "\n",
    "    predict_and_save_unlabel(\n",
    "        model,\n",
    "        unlabel_folder=unlabel_img,\n",
    "        save_folder='road2/unlabel_pred_refine_2',\n",
    "        device=device,\n",
    "        size=(256,256)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
